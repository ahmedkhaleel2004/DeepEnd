{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('github_users_dataset.csv')\n",
    "\n",
    "# Drop rows with missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# drop rows where the first column is \"role\"\n",
    "data = data[data['role'] != 'role']\n",
    "\n",
    "# Preprocess 'experience_level' using Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "data['experience_level'] = label_encoder.fit_transform(data['experience_level'])\n",
    "\n",
    "# Tokenize 'role', 'languages', 'tech_keywords', and 'projects'\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(data['role'])\n",
    "tokenizer.fit_on_texts(data['languages'].apply(lambda x: ', '.join(x)))\n",
    "tokenizer.fit_on_texts(data['tech_keywords'].apply(lambda x: ', '.join(x)))\n",
    "tokenizer.fit_on_texts(data['projects'].apply(lambda x: ', '.join(x)))\n",
    "\n",
    "# Function to convert texts to padded sequences\n",
    "def texts_to_padded_sequences(texts):\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    return pad_sequences(sequences, maxlen=100)\n",
    "\n",
    "# Convert columns to padded sequences\n",
    "data['role'] = data['role'].apply(lambda x: texts_to_padded_sequences([x])[0])\n",
    "data['languages'] = data['languages'].apply(lambda x: texts_to_padded_sequences([', '.join(x)])[0])\n",
    "data['tech_keywords'] = data['tech_keywords'].apply(lambda x: texts_to_padded_sequences([', '.join(x)])[0])\n",
    "data['projects'] = data['projects'].apply(lambda x: texts_to_padded_sequences([', '.join(x)])[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['role', 'experience_level', 'languages', 'tech_keywords']]\n",
    "y = data['projects']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " role_input (InputLayer)     [(None, 100)]                0         []                            \n",
      "                                                                                                  \n",
      " languages_input (InputLaye  [(None, 100)]                0         []                            \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " tech_keywords_input (Input  [(None, 100)]                0         []                            \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)     (None, 100, 64)              640000    ['role_input[0][0]',          \n",
      "                                                                     'languages_input[0][0]',     \n",
      "                                                                     'tech_keywords_input[0][0]'] \n",
      "                                                                                                  \n",
      " lstm_9 (LSTM)               (None, 32)                   12416     ['embedding_3[0][0]']         \n",
      "                                                                                                  \n",
      " experience_level_input (In  [(None, 1)]                  0         []                            \n",
      " putLayer)                                                                                        \n",
      "                                                                                                  \n",
      " lstm_10 (LSTM)              (None, 32)                   12416     ['embedding_3[1][0]']         \n",
      "                                                                                                  \n",
      " lstm_11 (LSTM)              (None, 32)                   12416     ['embedding_3[2][0]']         \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 97)                   0         ['lstm_9[0][0]',              \n",
      " )                                                                   'experience_level_input[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'lstm_10[0][0]',             \n",
      "                                                                     'lstm_11[0][0]']             \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 64)                   6272      ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 64)                   0         ['dense_6[0][0]']             \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 100)                  6500      ['dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 690020 (2.63 MB)\n",
      "Trainable params: 690020 (2.63 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define inputs\n",
    "role_input = Input(shape=(100,), name=\"role_input\")\n",
    "exp_input = Input(shape=(1,), name=\"experience_level_input\")\n",
    "lang_input = Input(shape=(100,), name=\"languages_input\")\n",
    "tech_input = Input(shape=(100,), name=\"tech_keywords_input\")\n",
    "\n",
    "# Embeddings for text inputs\n",
    "embedding = Embedding(input_dim=10000, output_dim=64)\n",
    "role_embedding = embedding(role_input)\n",
    "lang_embedding = embedding(lang_input)\n",
    "tech_embedding = embedding(tech_input)\n",
    "\n",
    "# LSTM layers for text inputs\n",
    "role_lstm = LSTM(32)(role_embedding)\n",
    "lang_lstm = LSTM(32)(lang_embedding)\n",
    "tech_lstm = LSTM(32)(tech_embedding)\n",
    "\n",
    "# Concatenate all inputs\n",
    "concat = Concatenate()([role_lstm, exp_input, lang_lstm, tech_lstm])\n",
    "\n",
    "# Dense layers\n",
    "dense1 = Dense(64, activation='relu')(concat)\n",
    "dropout = Dropout(0.5)(dense1)\n",
    "output = Dense(100, activation='softmax')(dropout)\n",
    "\n",
    "# Build and compile the model\n",
    "model = Model(inputs=[role_input, exp_input, lang_input, tech_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for training\n",
    "X_train_dict = {\n",
    "    'role_input': np.array(X_train['role'].tolist()),\n",
    "    'experience_level_input': np.array(X_train['experience_level']),\n",
    "    'languages_input': np.array(X_train['languages'].tolist()),\n",
    "    'tech_keywords_input': np.array(X_train['tech_keywords'].tolist())\n",
    "}\n",
    "y_train_array = np.array(y_train.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/12 [==============================] - 6s 140ms/step - loss: 6096.3828 - accuracy: 0.0136 - val_loss: 5784.7583 - val_accuracy: 0.0215\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 6172.4219 - accuracy: 0.0081 - val_loss: 5916.1958 - val_accuracy: 0.0215\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 7404.2559 - accuracy: 0.0081 - val_loss: 6881.2310 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 10056.5508 - accuracy: 0.0000e+00 - val_loss: 8893.1094 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 15893.1387 - accuracy: 0.0000e+00 - val_loss: 12593.0508 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 24155.4844 - accuracy: 0.0136 - val_loss: 17949.9219 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 31588.8203 - accuracy: 0.0108 - val_loss: 24592.5645 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 41672.2539 - accuracy: 0.0108 - val_loss: 32196.4785 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 53029.8477 - accuracy: 0.0190 - val_loss: 40999.1797 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 66945.3281 - accuracy: 0.0081 - val_loss: 50571.5273 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x144f4df10>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train_dict, y_train_array, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "def preprocess_user_data(role, experience_level, languages, tech_keywords):\n",
    "    role_seq = texts_to_padded_sequences([role])[0]\n",
    "    exp_level_seq = label_encoder.transform([experience_level])[0]\n",
    "    lang_seq = texts_to_padded_sequences([', '.join(languages)])[0]\n",
    "    tech_seq = texts_to_padded_sequences([', '.join(tech_keywords)])[0]\n",
    "    return {\n",
    "        'role_input': np.array([role_seq]),\n",
    "        'experience_level_input': np.array([exp_level_seq]),\n",
    "        'languages_input': np.array([lang_seq]),\n",
    "        'tech_keywords_input': np.array([tech_seq])\n",
    "    }\n",
    "\n",
    "# Example user data\n",
    "example_user = preprocess_user_data(\n",
    "    role=\"@MajorLeagueBaseball Kubernetes SME & Cloud Platform Engineer; @cncf Ambassador Emeritus\",\n",
    "    experience_level=\"Intermediate\",\n",
    "    languages=['Shell', 'Dockerfile', 'Go', 'Makefile', 'JavaScript'],\n",
    "    tech_keywords=['controller', 'docker', 'chaperone', 'external', 'automerge', 'action', 'pull', 'tools', 'merged', 'akuity']\n",
    ")\n",
    "\n",
    "# Predict\n",
    "predicted_projects = model.predict(example_user)\n",
    "# Convert predictions to actual project descriptions (you need a reverse mapping from sequences to text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'predicted_projects' is the output of your model\n",
    "top_n = 5  # Number of top tokens to consider for each project description\n",
    "top_project_tokens = np.argsort(predicted_projects, axis=-1)[:, -top_n:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['⃣ m 的 computer principal']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a reverse mapping from token to word\n",
    "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
    "\n",
    "# Function to convert tokens to words\n",
    "def tokens_to_words(tokens):\n",
    "    words = [reverse_word_map.get(token, '') for token in tokens]\n",
    "    return ' '.join(words).strip()\n",
    "\n",
    "# Convert top tokens to words\n",
    "project_descriptions = [tokens_to_words(tokens) for tokens in top_project_tokens]\n",
    "project_descriptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['⃣ m 的 computer principal']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_description(description):\n",
    "    # Example function to clean up descriptions - customize as needed\n",
    "    words = description.split()\n",
    "    # Remove duplicates, keep the order\n",
    "    cleaned_words = sorted(set(words), key=lambda x: words.index(x))\n",
    "    return ' '.join(cleaned_words)\n",
    "\n",
    "cleaned_project_descriptions = [clean_description(desc) for desc in project_descriptions]\n",
    "cleaned_project_descriptions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
