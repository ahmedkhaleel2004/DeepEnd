{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ahmed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('github_users_dataset.csv')\n",
    "\n",
    "# Drop rows with missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# drop rows where the first column is \"role\"\n",
    "data = data[data['role'] != 'role']\n",
    "\n",
    "# Preprocess 'experience_level' using Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "data['experience_level'] = label_encoder.fit_transform(data['experience_level'])\n",
    "\n",
    "# Tokenize 'role', 'languages', 'tech_keywords', and 'projects'\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(data['role'])\n",
    "tokenizer.fit_on_texts(data['languages'].apply(lambda x: ', '.join(x)))\n",
    "tokenizer.fit_on_texts(data['tech_keywords'].apply(lambda x: ', '.join(x)))\n",
    "tokenizer.fit_on_texts(data['projects'].apply(lambda x: ', '.join(x)))\n",
    "\n",
    "# Function to convert texts to padded sequences\n",
    "def texts_to_padded_sequences(texts):\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    return pad_sequences(sequences, maxlen=100)\n",
    "\n",
    "# Convert columns to padded sequences\n",
    "data['role'] = data['role'].apply(lambda x: texts_to_padded_sequences([x])[0])\n",
    "data['languages'] = data['languages'].apply(lambda x: texts_to_padded_sequences([', '.join(x)])[0])\n",
    "data['tech_keywords'] = data['tech_keywords'].apply(lambda x: texts_to_padded_sequences([', '.join(x)])[0])\n",
    "data['projects'] = data['projects'].apply(lambda x: texts_to_padded_sequences([', '.join(x)])[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['role', 'experience_level', 'languages', 'tech_keywords']]\n",
    "y = data['projects']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ahmed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ahmed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " role_input (InputLayer)     [(None, 100)]                0         []                            \n",
      "                                                                                                  \n",
      " languages_input (InputLaye  [(None, 100)]                0         []                            \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " tech_keywords_input (Input  [(None, 100)]                0         []                            \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 100, 64)              640000    ['role_input[0][0]',          \n",
      "                                                                     'languages_input[0][0]',     \n",
      "                                                                     'tech_keywords_input[0][0]'] \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 (None, 32)                   12416     ['embedding[0][0]']           \n",
      "                                                                                                  \n",
      " experience_level_input (In  [(None, 1)]                  0         []                            \n",
      " putLayer)                                                                                        \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               (None, 32)                   12416     ['embedding[1][0]']           \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)               (None, 32)                   12416     ['embedding[2][0]']           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 97)                   0         ['lstm[0][0]',                \n",
      "                                                                     'experience_level_input[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'lstm_1[0][0]',              \n",
      "                                                                     'lstm_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 64)                   6272      ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 64)                   0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 100)                  6500      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 690020 (2.63 MB)\n",
      "Trainable params: 690020 (2.63 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define inputs\n",
    "role_input = Input(shape=(100,), name=\"role_input\")\n",
    "exp_input = Input(shape=(1,), name=\"experience_level_input\")\n",
    "lang_input = Input(shape=(100,), name=\"languages_input\")\n",
    "tech_input = Input(shape=(100,), name=\"tech_keywords_input\")\n",
    "\n",
    "# Embeddings for text inputs\n",
    "embedding = Embedding(input_dim=10000, output_dim=64)\n",
    "role_embedding = embedding(role_input)\n",
    "lang_embedding = embedding(lang_input)\n",
    "tech_embedding = embedding(tech_input)\n",
    "\n",
    "# LSTM layers for text inputs\n",
    "role_lstm = LSTM(32)(role_embedding)\n",
    "lang_lstm = LSTM(32)(lang_embedding)\n",
    "tech_lstm = LSTM(32)(tech_embedding)\n",
    "\n",
    "# Concatenate all inputs\n",
    "concat = Concatenate()([role_lstm, exp_input, lang_lstm, tech_lstm])\n",
    "\n",
    "# Dense layers\n",
    "dense1 = Dense(64, activation='relu')(concat)\n",
    "dropout = Dropout(0.5)(dense1)\n",
    "output = Dense(100, activation='softmax')(dropout)\n",
    "\n",
    "# Build and compile the model\n",
    "model = Model(inputs=[role_input, exp_input, lang_input, tech_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for training\n",
    "X_train_dict = {\n",
    "    'role_input': np.array(X_train['role'].tolist()),\n",
    "    'experience_level_input': np.array(X_train['experience_level']),\n",
    "    'languages_input': np.array(X_train['languages'].tolist()),\n",
    "    'tech_keywords_input': np.array(X_train['tech_keywords'].tolist())\n",
    "}\n",
    "y_train_array = np.array(y_train.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\Users\\ahmed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ahmed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "6/6 [==============================] - 5s 203ms/step - loss: 6075.6880 - accuracy: 0.0284 - val_loss: 4293.2588 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6071.8779 - accuracy: 0.0114 - val_loss: 4294.0918 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 6093.5200 - accuracy: 0.0170 - val_loss: 4298.3638 - val_accuracy: 0.0222\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 6110.9395 - accuracy: 0.0057 - val_loss: 4333.1909 - val_accuracy: 0.0222\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 6416.8970 - accuracy: 0.0227 - val_loss: 4521.2368 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 7152.2246 - accuracy: 0.0000e+00 - val_loss: 4958.6772 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 9108.8760 - accuracy: 0.0341 - val_loss: 5581.4741 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 11072.5244 - accuracy: 0.0057 - val_loss: 6397.4751 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 13480.5684 - accuracy: 0.0114 - val_loss: 7503.2944 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 15815.1660 - accuracy: 0.0284 - val_loss: 8885.9482 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 18933.1816 - accuracy: 0.0057 - val_loss: 10568.5918 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 24034.1816 - accuracy: 0.0114 - val_loss: 12544.2637 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 26464.6191 - accuracy: 0.0057 - val_loss: 14703.3398 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 33493.4297 - accuracy: 0.0227 - val_loss: 17020.2480 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 36982.9727 - accuracy: 0.0057 - val_loss: 19501.0898 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 42403.7070 - accuracy: 0.0057 - val_loss: 22175.6797 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 44677.9883 - accuracy: 0.0057 - val_loss: 24911.7852 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 51122.6016 - accuracy: 0.0114 - val_loss: 27795.1777 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 58296.8516 - accuracy: 0.0057 - val_loss: 30801.4727 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 63975.2617 - accuracy: 0.0114 - val_loss: 33937.9766 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x224719032e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train_dict, y_train_array, epochs=20, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 813ms/step\n"
     ]
    }
   ],
   "source": [
    "def preprocess_user_data(role, experience_level, languages, tech_keywords):\n",
    "    role_seq = texts_to_padded_sequences([role])[0]\n",
    "    exp_level_seq = label_encoder.transform([experience_level])[0]\n",
    "    lang_seq = texts_to_padded_sequences([', '.join(languages)])[0]\n",
    "    tech_seq = texts_to_padded_sequences([', '.join(tech_keywords)])[0]\n",
    "    return {\n",
    "        'role_input': np.array([role_seq]),\n",
    "        'experience_level_input': np.array([exp_level_seq]),\n",
    "        'languages_input': np.array([lang_seq]),\n",
    "        'tech_keywords_input': np.array([tech_seq])\n",
    "    }\n",
    "\n",
    "# Example user data\n",
    "example_user = preprocess_user_data(\n",
    "    role=\"@MajorLeagueBaseball Kubernetes SME & Cloud Platform Engineer; @cncf Ambassador Emeritus\",\n",
    "    experience_level=\"Intermediate\",\n",
    "    languages=['Shell', 'Dockerfile', 'Go', 'Makefile', 'JavaScript'],\n",
    "    tech_keywords=['controller', 'docker', 'chaperone', 'external', 'automerge', 'action', 'pull', 'tools', 'merged', 'akuity']\n",
    ")\n",
    "\n",
    "# Predict\n",
    "predicted_projects = model.predict(example_user)\n",
    "# Convert predictions to actual project descriptions (you need a reverse mapping from sequences to text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'predicted_projects' is the output of your model\n",
    "top_n = 5  # Number of top tokens to consider for each project description\n",
    "top_project_tokens = np.argsort(predicted_projects, axis=-1)[:, -top_n:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['make g with research 的']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a reverse mapping from token to word\n",
    "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
    "\n",
    "# Function to convert tokens to words\n",
    "def tokens_to_words(tokens):\n",
    "    words = [reverse_word_map.get(token, '') for token in tokens]\n",
    "    return ' '.join(words).strip()\n",
    "\n",
    "# Convert top tokens to words\n",
    "project_descriptions = [tokens_to_words(tokens) for tokens in top_project_tokens]\n",
    "project_descriptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['make g with research 的']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_description(description):\n",
    "    # Example function to clean up descriptions - customize as needed\n",
    "    words = description.split()\n",
    "    # Remove duplicates, keep the order\n",
    "    cleaned_words = sorted(set(words), key=lambda x: words.index(x))\n",
    "    return ' '.join(cleaned_words)\n",
    "\n",
    "cleaned_project_descriptions = [clean_description(desc) for desc in project_descriptions]\n",
    "cleaned_project_descriptions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
